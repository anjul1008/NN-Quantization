{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f740a27",
   "metadata": {},
   "source": [
    "Quantization\n",
    "\n",
    "Ref: https://github.com/hkproj/quantization-notes/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4814059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1104,  1.0370, -0.1524,  1.5283],\n",
       "        [-0.5803,  0.4747, -0.0349, -0.4250],\n",
       "        [ 1.0839,  0.2665, -0.3881,  1.3272]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846fbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantization Types\n",
    "# 1. Symmetric Quantization\n",
    "# 2. Asymmetric Quantization\n",
    "\n",
    "def clamp(x, min_val, max_val):\n",
    "    x[x<min_val] = min_val  \n",
    "    x[x>max_val] = max_val\n",
    "    return x\n",
    "\n",
    "def asymmetric_quantization(x, num_bits):\n",
    "    # min-max quantization\n",
    "    alpha = torch.max(torch.abs(x))\n",
    "    beta = 0\n",
    "    scale = (alpha - beta) / (2**num_bits - 1)\n",
    "    zero_point = -1 * torch.round(beta / scale)\n",
    "    quantized = clamp(torch.round(x / scale), -2**(num_bits-1), 2**(num_bits-1) - 1)\n",
    "    return quantized, scale, zero_point\n",
    "\n",
    "def asymmetric_dequantization(x, scale, zero_point):\n",
    "    return x * scale + zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cff0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-2.1104,  1.0370, -0.1524,  1.5283],\n",
      "        [-0.5803,  0.4747, -0.0349, -0.4250],\n",
      "        [ 1.0839,  0.2665, -0.3881,  1.3272]])\n",
      "x_quantized: tensor([[-128.,  125.,  -18.,  127.],\n",
      "        [ -70.,   57.,   -4.,  -51.],\n",
      "        [ 127.,   32.,  -47.,  127.]])\n",
      "x_dequantized: tensor([[-1.0593,  1.0345, -0.1490,  1.0510],\n",
      "        [-0.5793,  0.4717, -0.0331, -0.4221],\n",
      "        [ 1.0510,  0.2648, -0.3890,  1.0510]])\n",
      "asymmetric quantization error:  tensor(1.4099)\n"
     ]
    }
   ],
   "source": [
    "print('x:', x)\n",
    "x_q, scale, zero_point = asymmetric_quantization(x, 8)\n",
    "print('x_quantized:', x_q)\n",
    "x_dequantized = asymmetric_dequantization(x_q, scale, zero_point)\n",
    "print('x_dequantized:', x_dequantized)\n",
    "# error SSE\n",
    "error = torch.sum((x - x_dequantized)**2)\n",
    "print('asymmetric quantization error: ', error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f0106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_quantization(x, num_bits):\n",
    "    alpha = torch.max(torch.abs(x))\n",
    "    scale = alpha / (2**(num_bits-1) - 1)\n",
    "    quantized = torch.round(x / scale)\n",
    "    return quantized, scale\n",
    "\n",
    "def symmetric_dequantization(x, scale):\n",
    "    return x * scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49906399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-2.1104,  1.0370, -0.1524,  1.5283],\n",
      "        [-0.5803,  0.4747, -0.0349, -0.4250],\n",
      "        [ 1.0839,  0.2665, -0.3881,  1.3272]])\n",
      "x_quantized: tensor([[-127.,   62.,   -9.,   92.],\n",
      "        [ -35.,   29.,   -2.,  -26.],\n",
      "        [  65.,   16.,  -23.,   80.]])\n",
      "x_dequantized: tensor([[-2.1104,  1.0303, -0.1496,  1.5288],\n",
      "        [-0.5816,  0.4819, -0.0332, -0.4320],\n",
      "        [ 1.0801,  0.2659, -0.3822,  1.3294]])\n",
      "symmetric quantization error:  tensor(0.0002)\n"
     ]
    }
   ],
   "source": [
    "print('x:', x)\n",
    "x_q, scale = symmetric_quantization(x, 8)\n",
    "print('x_quantized:', x_q)\n",
    "x_dequantized = symmetric_dequantization(x_q, scale)\n",
    "print('x_dequantized:', x_dequantized)\n",
    "# error SSE\n",
    "error = torch.sum((x - x_dequantized)**2)\n",
    "print('symmetric quantization error: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40f89539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def quantize_percentile(x, num_bits, percentile=99.9):\n",
    "    alpha = np.percentile(x.numpy(), percentile)\n",
    "    scale = alpha / (2**(num_bits-1) - 1)\n",
    "    quantized = torch.round(x / scale)\n",
    "    return quantized, scale\n",
    "\n",
    "def dequantize_percentile(x, scale):\n",
    "    return x * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e68557c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-2.1104,  1.0370, -0.1524,  1.5283],\n",
      "        [-0.5803,  0.4747, -0.0349, -0.4250],\n",
      "        [ 1.0839,  0.2665, -0.3881,  1.3272]])\n",
      "x_quantized: tensor([[-176.,   86.,  -13.,  127.],\n",
      "        [ -48.,   40.,   -3.,  -35.],\n",
      "        [  90.,   22.,  -32.,  110.]])\n",
      "x_dequantized: tensor([[-2.1149,  1.0334, -0.1562,  1.5261],\n",
      "        [-0.5768,  0.4807, -0.0360, -0.4206],\n",
      "        [ 1.0815,  0.2644, -0.3845,  1.3218]])\n",
      "symmetric quantization error:  tensor(0.0002)\n"
     ]
    }
   ],
   "source": [
    "print('x:', x)\n",
    "x_q, scale = quantize_percentile(x, 8)\n",
    "print('x_quantized:', x_q)\n",
    "x_dequantized = dequantize_percentile(x_q, scale)\n",
    "print('x_dequantized:', x_dequantized)\n",
    "# error SSE\n",
    "error = torch.sum((x - x_dequantized)**2)\n",
    "print('symmetric quantization error: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45047fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get SSE \n",
    "def comapre_quantization_methods(x, num_bits):\n",
    "    x_q, scale, zero_point = asymmetric_quantization(x, num_bits)\n",
    "    x_dequantized = asymmetric_dequantization(x_q, scale, zero_point)\n",
    "    asyn_error = torch.sum((x - x_dequantized)**2)\n",
    "    print('asymmetric quantization error: ', asyn_error)\n",
    "    \n",
    "    x_q, scale = symmetric_quantization(x, num_bits)\n",
    "    x_dequantized = symmetric_dequantization(x_q, scale)\n",
    "    sym_error = torch.sum((x - x_dequantized)**2)\n",
    "    print('symmetric quantization error: ', sym_error)\n",
    "    \n",
    "    x_q, scale = quantize_percentile(x, num_bits)\n",
    "    x_dequantized = dequantize_percentile(x_q, scale)\n",
    "    perc_error = torch.sum((x - x_dequantized)**2)\n",
    "    print('percentile quantization error: ', perc_error)    \n",
    "    return asyn_error, sym_error, perc_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "294ea35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asymmetric quantization error:  tensor(1.4099)\n",
      "symmetric quantization error:  tensor(0.0002)\n",
      "percentile quantization error:  tensor(0.0002)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4099), tensor(0.0002), tensor(0.0002))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n",
    "comapre_quantization_methods(x, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca1fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e0b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k2_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
